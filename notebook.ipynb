{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "# from engine import create_connection_string, get_engine\n",
    "# from query_loader import load_queries, load_sql_file\n",
    "# from update_or_append import update_or_append\n",
    "from sqlalchemy import exc as sqlalchemy_exc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL\n",
    "\n",
    "def create_connection_string(server: str) -> str:\n",
    "    \"\"\"Create a connection string based on the server type.\"\"\"\n",
    "    address = os.getenv(f'{server}_ADDRESS')\n",
    "    database = os.getenv(f'{server}_DATABASE')\n",
    "    driver = '{SQL Server}'\n",
    "    if server == 'DW':\n",
    "        return f'DRIVER={driver};SERVER={address};DATABASE={database};Trusted_Connection=yes;'\n",
    "    elif server == 'QN':\n",
    "        username = os.getenv(f'{server}_USERNAME')\n",
    "        password = os.getenv(f'{server}_PASSWORD')\n",
    "        return f'DRIVER={driver};SERVER={address};DATABASE={database};UID={username};PWD={password};'\n",
    "    elif server == \"DM\":\n",
    "        username = os.getenv(f'{server}_USERNAME')\n",
    "        password = os.getenv(f'{server}_PASSWORD')\n",
    "        return f'DRIVER={driver};SERVER={address};DATABASE={database};UID={username};PWD={password};'\n",
    "    else:\n",
    "        raise ValueError(f\"Server {server} configuration not found\")\n",
    "\n",
    "def get_engine(connection_string: str):\n",
    "    \"\"\"Get a SQLAlchemy engine.\"\"\"\n",
    "    url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "    return create_engine(url, fast_executemany=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "def load_queries(filepath: str) -> Dict[str, Dict]:\n",
    "    \"\"\"Load queries from a JSON file.\"\"\"\n",
    "    with open(filepath) as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "def load_sql_file(filepath: str) -> str:\n",
    "    \"\"\"Load SQL query from a file.\"\"\"\n",
    "    with open(filepath) as sql_file:\n",
    "        return sql_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartsheet\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def update_or_append(sheet_id: str, df: pd.DataFrame, primary_column_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Update or append rows to a Smartsheet based on the primary column value.\n",
    "\n",
    "    Args:\n",
    "        sheet_id (str): ID of the Smartsheet to update/append.\n",
    "        df (pd.DataFrame): DataFrame containing the data to be updated/appended.\n",
    "        primary_column_name (str): Name of the primary column in the DataFrame and Smartsheet.\n",
    "\n",
    "    This function updates rows in a Smartsheet if a matching primary column value is found.\n",
    "    If no match is found, it appends the row as a new entry. Errors are logged for troubleshooting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_key = os.getenv('SMARTSHEET_API_KEY')\n",
    "\n",
    "        # Initialize client\n",
    "        smartsheet_client = smartsheet.Smartsheet(api_key)\n",
    "\n",
    "        # Load the entire sheet\n",
    "        sheet = smartsheet_client.Sheets.get_sheet(sheet_id)\n",
    "\n",
    "        # Log the sheet ID and name\n",
    "        # If the sheet is not found, log an error\n",
    "        if not sheet:\n",
    "            logging.error(f\"Smartsheet ID {sheet_id} not found.\")\n",
    "            return False\n",
    "        else:\n",
    "            logging.info(f\"Loaded Smartsheet {sheet.name} with ID {sheet_id}\")\n",
    "\n",
    "        # Mapping DataFrame columns to Smartsheet column IDs\n",
    "        column_map = {col.title: col.id for col in sheet.columns}\n",
    "\n",
    "        # Get the primary columns IDs\n",
    "        primary_column_id = column_map.get(primary_column_name)\n",
    "\n",
    "        # If not all columns in the DataFrame are in the Smartsheet, log an error\n",
    "        if not all(col in column_map for col in df.columns):\n",
    "            logging.error(f\"Not all columns in the DataFrame are in the Smartsheet. Please check the column names.\")\n",
    "            return False\n",
    "\n",
    "        # Prepare rows to update or add\n",
    "        rows_to_update = []\n",
    "        rows_to_add = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # Find the row in the Smartsheet that matches the primary column value\n",
    "            existing_row = next((r for r in sheet.rows if r.get_column(primary_column_id).value == row[primary_column_name]), None)\n",
    "\n",
    "            new_smartsheet_row = smartsheet.models.Row()\n",
    "\n",
    "            # Add the cells to the row\n",
    "            new_smartsheet_row.cells = [smartsheet.models.Cell({\n",
    "                'column_id': column_map[col],\n",
    "                'value': row[col]\n",
    "            }) for col in df.columns]\n",
    "\n",
    "            if existing_row:\n",
    "                # If the values are the same, skip the row. Get columns using the column_map\n",
    "                if all(existing_row.get_column(column_map[col]).value == row[col] for col in df.columns):\n",
    "                    # Log the skipped row\n",
    "                    logging.info(f\"{sheet.name}: Skipped row with {primary_column_name} value {row[primary_column_name]}\")\n",
    "                    continue\n",
    "                new_smartsheet_row.id = existing_row.id\n",
    "                rows_to_update.append(new_smartsheet_row)\n",
    "            else:\n",
    "                new_smartsheet_row.to_bottom = True\n",
    "                rows_to_add.append(new_smartsheet_row)\n",
    "\n",
    "        # Update existing rows\n",
    "        if rows_to_update:\n",
    "            smartsheet_client.Sheets.update_rows(sheet_id, rows_to_update)\n",
    "            logging.info(f\"Updated {len(rows_to_update)} rows in Smartsheet ID {sheet_id}\")\n",
    "\n",
    "        # Add new rows\n",
    "        if rows_to_add:\n",
    "            smartsheet_client.Sheets.add_rows(sheet_id, rows_to_add)\n",
    "            logging.info(f\"Added {len(rows_to_add)} new rows to Smartsheet ID {sheet_id}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred in update_or_append: {e}\", exc_info=True)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(filename='logs.txt', level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "def app():\n",
    "    queries = load_queries('queries/queries.json')\n",
    "\n",
    "    # Create database engines\n",
    "    dw_engine = get_engine(create_connection_string('DW'))\n",
    "    qnxt_engine = get_engine(create_connection_string('QN'))\n",
    "    dm_engine = get_engine(create_connection_string('DM'))\n",
    "\n",
    "    # Iterate over queries\n",
    "    for name, query in queries.items():\n",
    "        try:\n",
    "            process_query(name, query, dw_engine, qnxt_engine, dm_engine)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {name}: {e}\")\n",
    "\n",
    "def process_query(name: str, query: dict, dw_engine, qnxt_engine, dm_engine):\n",
    "    \"\"\"Process a single query.\"\"\"\n",
    "    if query['database'] == 'DW':\n",
    "        engine = dw_engine\n",
    "    elif query['database'] == 'QN':\n",
    "        engine = qnxt_engine\n",
    "    elif query['database'] == 'DM':\n",
    "        engine = dm_engine\n",
    "        \n",
    "    sql = load_sql_file(f'queries/{query[\"sql\"]}')\n",
    "\n",
    "    try:\n",
    "        df = pd.read_sql(sql, engine)\n",
    "        update_or_append(query['id'], df, query['primary_column'])\n",
    "    except sqlalchemy_exc.SQLAlchemyError as e:\n",
    "        logging.error(f\"SQLAlchemyError in query {name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
